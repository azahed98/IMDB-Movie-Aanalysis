{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    def __init__(self, data_names, data, label_names, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.data_names = data_names\n",
    "        self.label_names = label_names\n",
    "        \n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        return [(n, x.shape) for n, x in zip(self.data_names, self.data)]\n",
    "    \n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        return [(n, x.shape) for n, x in zip(self.label_names, self.label)]\n",
    "    \n",
    "class DataIter(mx.io.DataIter):\n",
    "    def __init__(self, fname, batch_size):\n",
    "        super(DataIter, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data = []\n",
    "        openfile = open(fname)\n",
    "        for line in openfile:\n",
    "            tks = line.strip().split('\\t')\n",
    "            if len(tks) != 4:\n",
    "                continue\n",
    "            self.data.append((int(tks[0]), int(tks[1]), float(tks[2])))\n",
    "        self.provide_data = [('user', (batch_size, )), ('item', (batch_size, ))]\n",
    "        self.provide_label = [('score', (self.batch_size, ))]\n",
    "        openfile.close()\n",
    "\n",
    "    def __iter__(self):\n",
    "        for k in range(len(self.data) // self.batch_size):\n",
    "            users = []\n",
    "            items = []\n",
    "            scores = []\n",
    "            for i in range(self.batch_size):\n",
    "                j = k * self.batch_size + i\n",
    "                user, item, score = self.data[j]\n",
    "                users.append(user)\n",
    "                items.append(item)\n",
    "                scores.append(score)\n",
    "\n",
    "            data_all = [mx.nd.array(users), mx.nd.array(items)]\n",
    "            label_all = [mx.nd.array(scores)]\n",
    "            data_names = ['user', 'item']\n",
    "            label_names = ['score']\n",
    "\n",
    "            data_batch = Batch(data_names, data_all, label_names, label_all)\n",
    "            yield data_batch\n",
    "\n",
    "    def reset(self):\n",
    "        random.shuffle(self.data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "if not os.path.exists('ml-100k.zip'):\n",
    "    urllib.request.urlretrieve('http://files.grouplens.org/datasets/movielens/ml-100k.zip', 'ml-100k.zip')\n",
    "with zipfile.ZipFile(\"ml-100k.zip\",\"r\") as f:\n",
    "    f.extractall(\"./\")\n",
    "def get_data(batch_size):\n",
    "    return (DataIter('./ml-100k/u1.base', batch_size), DataIter('./ml-100k/u1.test', batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1683)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_id(fname):\n",
    "    mu = 0\n",
    "    mi = 0\n",
    "    openfile = open(fname)\n",
    "    for line in openfile:\n",
    "        tks = line.strip().split('\\t')\n",
    "        if len(tks) != 4:\n",
    "            continue\n",
    "        mu = max(mu, int(tks[0]))\n",
    "        mi = max(mi, int(tks[1]))\n",
    "    return mu + 1, mi + 1\n",
    "    openfile.close()\n",
    "max_user, max_item = max_id('./ml-100k/u.data')\n",
    "(max_user, max_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def RMSE(label, pred):\n",
    "    ret = 0.0\n",
    "    n = 0.0\n",
    "    pred = pred.flatten()\n",
    "    for i in range(len(label)):\n",
    "        ret += (label[i] - pred[i]) * (label[i] - pred[i])\n",
    "        n += 1.0\n",
    "    return math.sqrt(ret / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(network, batch_size, num_epoch, learning_rate):\n",
    "    model = mx.model.FeedForward(\n",
    "        ctx = mx.cpu(0),  \n",
    "        symbol = network,\n",
    "        num_epoch = num_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        wd = 0.0001,\n",
    "        momentum = 0.9)\n",
    "\n",
    "    batch_size = 64\n",
    "    train, test = get_data(batch_size)\n",
    "\n",
    "    import logging\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    model.fit(X = train, \n",
    "              eval_data = test,\n",
    "              eval_metric = RMSE,\n",
    "              batch_end_callback=mx.callback.Speedometer(batch_size, 20000/batch_size),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with [cpu(0)]\n",
      "INFO:root:Epoch[0] Batch [625]\tSpeed: 48308.15 samples/sec\tTrain-RMSE=3.696177\n",
      "INFO:root:Epoch[0] Batch [1250]\tSpeed: 37708.73 samples/sec\tTrain-RMSE=3.701101\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=1.043\n",
      "INFO:root:Epoch[0] Validation-RMSE=3.713837\n",
      "INFO:root:Epoch[1] Batch [625]\tSpeed: 47868.05 samples/sec\tTrain-RMSE=3.641698\n",
      "INFO:root:Epoch[1] Batch [1250]\tSpeed: 37602.91 samples/sec\tTrain-RMSE=2.876571\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=1.043\n",
      "INFO:root:Epoch[1] Validation-RMSE=2.393987\n",
      "INFO:root:Epoch[2] Batch [625]\tSpeed: 48601.04 samples/sec\tTrain-RMSE=1.831960\n",
      "INFO:root:Epoch[2] Batch [1250]\tSpeed: 40598.68 samples/sec\tTrain-RMSE=1.438286\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=1.000\n",
      "INFO:root:Epoch[2] Validation-RMSE=1.424105\n",
      "INFO:root:Epoch[3] Batch [625]\tSpeed: 46031.39 samples/sec\tTrain-RMSE=1.236698\n",
      "INFO:root:Epoch[3] Batch [1250]\tSpeed: 49320.35 samples/sec\tTrain-RMSE=1.153307\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=0.935\n",
      "INFO:root:Epoch[3] Validation-RMSE=1.201610\n",
      "INFO:root:Epoch[4] Batch [625]\tSpeed: 44586.10 samples/sec\tTrain-RMSE=1.086770\n",
      "INFO:root:Epoch[4] Batch [1250]\tSpeed: 51344.59 samples/sec\tTrain-RMSE=1.065604\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=0.931\n",
      "INFO:root:Epoch[4] Validation-RMSE=1.115599\n",
      "INFO:root:Epoch[5] Batch [625]\tSpeed: 43215.12 samples/sec\tTrain-RMSE=1.035600\n",
      "INFO:root:Epoch[5] Batch [1250]\tSpeed: 46336.53 samples/sec\tTrain-RMSE=1.020725\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=0.982\n",
      "INFO:root:Epoch[5] Validation-RMSE=1.072075\n",
      "INFO:root:Epoch[6] Batch [625]\tSpeed: 52274.59 samples/sec\tTrain-RMSE=1.005667\n",
      "INFO:root:Epoch[6] Batch [1250]\tSpeed: 34253.92 samples/sec\tTrain-RMSE=1.002862\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=1.059\n",
      "INFO:root:Epoch[6] Validation-RMSE=1.049035\n",
      "INFO:root:Epoch[7] Batch [625]\tSpeed: 48055.56 samples/sec\tTrain-RMSE=0.989031\n",
      "INFO:root:Epoch[7] Batch [1250]\tSpeed: 39911.69 samples/sec\tTrain-RMSE=0.990506\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=1.014\n",
      "INFO:root:Epoch[7] Validation-RMSE=1.036378\n",
      "INFO:root:Epoch[8] Batch [625]\tSpeed: 45622.10 samples/sec\tTrain-RMSE=0.979576\n",
      "INFO:root:Epoch[8] Batch [1250]\tSpeed: 47863.38 samples/sec\tTrain-RMSE=0.981722\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=0.941\n",
      "INFO:root:Epoch[8] Validation-RMSE=1.023457\n",
      "INFO:root:Epoch[9] Batch [625]\tSpeed: 38545.59 samples/sec\tTrain-RMSE=0.973815\n",
      "INFO:root:Epoch[9] Batch [1250]\tSpeed: 51067.84 samples/sec\tTrain-RMSE=0.973585\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=1.002\n",
      "INFO:root:Epoch[9] Validation-RMSE=1.020611\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "def plain_net(k):\n",
    "    # input\n",
    "    user = mx.symbol.Variable('user')\n",
    "    item = mx.symbol.Variable('item')\n",
    "    score = mx.symbol.Variable('score')\n",
    "    # user feature lookup\n",
    "    user = mx.symbol.Embedding(data = user, input_dim = max_user, output_dim = k) \n",
    "    # item feature lookup\n",
    "    item = mx.symbol.Embedding(data = item, input_dim = max_item, output_dim = k)\n",
    "    # predict by the inner product, which is elementwise product and then sum\n",
    "    pred = user * item\n",
    "    pred = mx.symbol.sum_axis(data = pred, axis = 1)\n",
    "    pred = mx.symbol.Flatten(data = pred)\n",
    "    # loss layer\n",
    "    pred = mx.symbol.LinearRegressionOutput(data = pred, label = score)\n",
    "    return pred\n",
    "\n",
    "train(plain_net(64), batch_size=64, num_epoch=10, learning_rate=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with [cpu(0)]\n",
      "INFO:root:Epoch[0] Batch [625]\tSpeed: 36553.25 samples/sec\tTrain-RMSE=1.196051\n",
      "INFO:root:Epoch[0] Batch [1250]\tSpeed: 36555.00 samples/sec\tTrain-RMSE=0.982350\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=1.188\n",
      "INFO:root:Epoch[0] Validation-RMSE=0.984141\n",
      "INFO:root:Epoch[1] Batch [625]\tSpeed: 29850.34 samples/sec\tTrain-RMSE=0.957677\n",
      "INFO:root:Epoch[1] Batch [1250]\tSpeed: 31321.70 samples/sec\tTrain-RMSE=0.967071\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=1.404\n",
      "INFO:root:Epoch[1] Validation-RMSE=0.974737\n",
      "INFO:root:Epoch[2] Batch [625]\tSpeed: 36233.60 samples/sec\tTrain-RMSE=0.946655\n",
      "INFO:root:Epoch[2] Batch [1250]\tSpeed: 30117.94 samples/sec\tTrain-RMSE=0.948026\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=1.313\n",
      "INFO:root:Epoch[2] Validation-RMSE=0.964631\n",
      "INFO:root:Epoch[3] Batch [625]\tSpeed: 32270.70 samples/sec\tTrain-RMSE=0.946844\n",
      "INFO:root:Epoch[3] Batch [1250]\tSpeed: 26990.44 samples/sec\tTrain-RMSE=0.949214\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=1.459\n",
      "INFO:root:Epoch[3] Validation-RMSE=0.961480\n",
      "INFO:root:Epoch[4] Batch [625]\tSpeed: 34703.42 samples/sec\tTrain-RMSE=0.936587\n",
      "INFO:root:Epoch[4] Batch [1250]\tSpeed: 30388.87 samples/sec\tTrain-RMSE=0.949037\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=1.349\n",
      "INFO:root:Epoch[4] Validation-RMSE=0.976810\n",
      "INFO:root:Epoch[5] Batch [625]\tSpeed: 34879.95 samples/sec\tTrain-RMSE=0.937820\n",
      "INFO:root:Epoch[5] Batch [1250]\tSpeed: 29704.15 samples/sec\tTrain-RMSE=0.945136\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=1.335\n",
      "INFO:root:Epoch[5] Validation-RMSE=0.962484\n",
      "INFO:root:Epoch[6] Batch [625]\tSpeed: 26435.92 samples/sec\tTrain-RMSE=0.944161\n",
      "INFO:root:Epoch[6] Batch [1250]\tSpeed: 28691.44 samples/sec\tTrain-RMSE=0.943309\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=1.545\n",
      "INFO:root:Epoch[6] Validation-RMSE=1.002146\n",
      "INFO:root:Epoch[7] Batch [625]\tSpeed: 29879.59 samples/sec\tTrain-RMSE=0.941414\n",
      "INFO:root:Epoch[7] Batch [1250]\tSpeed: 35585.18 samples/sec\tTrain-RMSE=0.940209\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=1.324\n",
      "INFO:root:Epoch[7] Validation-RMSE=0.976096\n",
      "INFO:root:Epoch[8] Batch [625]\tSpeed: 32410.81 samples/sec\tTrain-RMSE=0.936386\n",
      "INFO:root:Epoch[8] Batch [1250]\tSpeed: 27545.47 samples/sec\tTrain-RMSE=0.939569\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=1.434\n",
      "INFO:root:Epoch[8] Validation-RMSE=0.958939\n",
      "INFO:root:Epoch[9] Batch [625]\tSpeed: 25590.57 samples/sec\tTrain-RMSE=0.939817\n",
      "INFO:root:Epoch[9] Batch [1250]\tSpeed: 36463.01 samples/sec\tTrain-RMSE=0.939947\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=1.422\n",
      "INFO:root:Epoch[9] Validation-RMSE=0.962412\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "def get_one_layer_mlp(hidden, k):\n",
    "    # input\n",
    "    user = mx.symbol.Variable('user')\n",
    "    item = mx.symbol.Variable('item')\n",
    "    score = mx.symbol.Variable('score')\n",
    "    # user latent features\n",
    "    user = mx.symbol.Embedding(data = user, input_dim = max_user, output_dim = k)\n",
    "    user = mx.symbol.Activation(data = user, act_type=\"relu\")\n",
    "    user = mx.symbol.FullyConnected(data = user, num_hidden = hidden)\n",
    "    # item latent features\n",
    "    item = mx.symbol.Embedding(data = item, input_dim = max_item, output_dim = k)\n",
    "    item = mx.symbol.Activation(data = item, act_type=\"relu\")\n",
    "    item = mx.symbol.FullyConnected(data = item, num_hidden = hidden)\n",
    "    # predict by the inner product\n",
    "    pred = user * item\n",
    "    pred = mx.symbol.sum_axis(data = pred, axis = 1)\n",
    "    pred = mx.symbol.Flatten(data = pred)\n",
    "    # loss layer\n",
    "    pred = mx.symbol.LinearRegressionOutput(data = pred, label = score)\n",
    "    return pred\n",
    "\n",
    "train(get_one_layer_mlp(64, 64), batch_size=64, num_epoch=10, learning_rate=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with [cpu(0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [625]\tSpeed: 5518.09 samples/sec\tTrain-RMSE=1.145038\n",
      "INFO:root:Epoch[0] Batch [1250]\tSpeed: 5441.72 samples/sec\tTrain-RMSE=0.983353\n",
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=7.391\n",
      "INFO:root:Epoch[0] Validation-RMSE=0.994780\n",
      "INFO:root:Epoch[1] Batch [625]\tSpeed: 5410.85 samples/sec\tTrain-RMSE=0.954181\n",
      "INFO:root:Epoch[1] Batch [1250]\tSpeed: 5341.76 samples/sec\tTrain-RMSE=0.955525\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=7.529\n",
      "INFO:root:Epoch[1] Validation-RMSE=0.963774\n",
      "INFO:root:Epoch[2] Batch [625]\tSpeed: 5020.56 samples/sec\tTrain-RMSE=0.940759\n",
      "INFO:root:Epoch[2] Batch [1250]\tSpeed: 5705.73 samples/sec\tTrain-RMSE=0.948125\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=7.575\n",
      "INFO:root:Epoch[2] Validation-RMSE=0.959221\n",
      "INFO:root:Epoch[3] Batch [625]\tSpeed: 5144.07 samples/sec\tTrain-RMSE=0.939967\n",
      "INFO:root:Epoch[3] Batch [1250]\tSpeed: 5263.33 samples/sec\tTrain-RMSE=0.947161\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=7.785\n",
      "INFO:root:Epoch[3] Validation-RMSE=0.961736\n",
      "INFO:root:Epoch[4] Batch [625]\tSpeed: 5344.91 samples/sec\tTrain-RMSE=0.935569\n",
      "INFO:root:Epoch[4] Batch [1250]\tSpeed: 5373.81 samples/sec\tTrain-RMSE=0.938915\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=7.564\n",
      "INFO:root:Epoch[4] Validation-RMSE=0.963310\n",
      "INFO:root:Epoch[5] Batch [625]\tSpeed: 5501.67 samples/sec\tTrain-RMSE=0.932145\n",
      "INFO:root:Epoch[5] Batch [1250]\tSpeed: 5499.32 samples/sec\tTrain-RMSE=0.941358\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=7.380\n",
      "INFO:root:Epoch[5] Validation-RMSE=0.971672\n",
      "INFO:root:Epoch[6] Batch [625]\tSpeed: 5025.75 samples/sec\tTrain-RMSE=0.932346\n",
      "INFO:root:Epoch[6] Batch [1250]\tSpeed: 5109.79 samples/sec\tTrain-RMSE=0.939989\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=7.985\n",
      "INFO:root:Epoch[6] Validation-RMSE=0.955739\n",
      "INFO:root:Epoch[7] Batch [625]\tSpeed: 5231.36 samples/sec\tTrain-RMSE=0.937618\n",
      "INFO:root:Epoch[7] Batch [1250]\tSpeed: 5209.75 samples/sec\tTrain-RMSE=0.933283\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=7.763\n",
      "INFO:root:Epoch[7] Validation-RMSE=0.954642\n",
      "INFO:root:Epoch[8] Batch [625]\tSpeed: 5332.03 samples/sec\tTrain-RMSE=0.930568\n",
      "INFO:root:Epoch[8] Batch [1250]\tSpeed: 5315.32 samples/sec\tTrain-RMSE=0.928952\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=7.600\n",
      "INFO:root:Epoch[8] Validation-RMSE=0.950346\n",
      "INFO:root:Epoch[9] Batch [625]\tSpeed: 5160.38 samples/sec\tTrain-RMSE=0.926405\n",
      "INFO:root:Epoch[9] Batch [1250]\tSpeed: 5093.76 samples/sec\tTrain-RMSE=0.936903\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=7.894\n",
      "INFO:root:Epoch[9] Validation-RMSE=1.030685\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "def get_one_layer_dropout_mlp(hidden, k):\n",
    "    # input\n",
    "    user = mx.symbol.Variable('user')\n",
    "    item = mx.symbol.Variable('item')\n",
    "    score = mx.symbol.Variable('score')\n",
    "    # user latent features\n",
    "    user = mx.symbol.Embedding(data = user, input_dim = max_user, output_dim = k)\n",
    "    user = mx.symbol.Activation(data = user, act_type=\"relu\")\n",
    "    user = mx.symbol.FullyConnected(data = user, num_hidden = hidden)\n",
    "    user = mx.symbol.Dropout(data=user, p=0.5)\n",
    "    # item latent features\n",
    "    item = mx.symbol.Embedding(data = item, input_dim = max_item, output_dim = k)\n",
    "    item = mx.symbol.Activation(data = item, act_type=\"relu\")\n",
    "    item = mx.symbol.FullyConnected(data = item, num_hidden = hidden)\n",
    "    item = mx.symbol.Dropout(data=item, p=0.5)    \n",
    "    # predict by the inner product\n",
    "    pred = user * item\n",
    "    pred = mx.symbol.sum_axis(data = pred, axis = 1)\n",
    "    pred = mx.symbol.Flatten(data = pred)\n",
    "    # loss layer\n",
    "    pred = mx.symbol.LinearRegressionOutput(data = pred, label = score)\n",
    "    return pred\n",
    "train(get_one_layer_mlp(256, 512), batch_size=64, num_epoch=10, learning_rate=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
